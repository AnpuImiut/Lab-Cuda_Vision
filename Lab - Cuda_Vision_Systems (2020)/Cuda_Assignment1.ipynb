{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuda-vision Lab - Assignment 1\n",
    "##    Team Members:\n",
    "    - Mst.Mahfuja Akter\n",
    "    - Heiko Schmidt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for the load_mnist function\n",
    "import os, struct\n",
    "from array import array as pyarray\n",
    "# general import\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining softmax function as activation function\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got provided this function in the lecture \"Deep Learning for visual recognition\".\n",
    "It reads and open the data according to following structere:\n",
    "\n",
    "# TRAINING SET LABEL FILE (train-labels-idx1-ubyte):\n",
    "|   [offset]   |   [type]     |     [value]   |     [description]   |\n",
    "|-|-|-|-|\n",
    "|0000   |  32 bit integer | 0x00000801(2049)| magic number (MSB first)|\n",
    "|0004  |   32 bit integer | 60000        |    number of items|\n",
    "|0008  |   unsigned byte  | ??           |    label   |\n",
    "|0009   |  unsigned byte |  ??          |     label   |\n",
    "||........||\n",
    "|xxxx   |  unsigned byte  | ??           |    label\n",
    "\n",
    "The labels values are 0 to 9.\n",
    "# TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\n",
    "|   [offset]   |   [type]     |     [value]   |     [description]   |\n",
    "|-|-|-|-|\n",
    "|0000  |   32 bit integer | 0x00000803(2051)| magic number|\n",
    "0004   |  32 bit integer | 60000           | number of images|\n",
    "0008   |  32 bit integer | 28       |        number of rows|\n",
    "0012    | 32 bit integer | 28        |       number of columns|\n",
    "0016   |  unsigned byte |  ??       |        pixel|\n",
    "0017   |  unsigned byte |  ??   |           pixel|\n",
    "||........||\n",
    "|xxxx  |   unsigned byte |  ??        |       pixel|\n",
    "\n",
    "Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "# TEST SET LABEL FILE (t10k-labels-idx1-ubyte):\n",
    "|   [offset]   |   [type]     |     [value]   |     [description]   |\n",
    "|-|-|-|-|\n",
    "|0000  |   32 bit integer | 0x00000801(2049)| magic number (MSB first)|\n",
    "|0004  |   32 bit integer | 10000      |      number of items|\n",
    "|0008   |  unsigned byte |  ??         |      label|\n",
    "|0009  |   unsigned byte |  ??         |      label|\n",
    "||........||\n",
    "|xxxx   |  unsigned byte  | ??         |      label|\n",
    "\n",
    "The labels values are 0 to 9.\n",
    "# TEST SET IMAGE FILE (t10k-images-idx3-ubyte):\n",
    "|   [offset]   |   [type]     |     [value]   |     [description]   |\n",
    "|-|-|-|-|\n",
    "|0000   |  32 bit integer|  0x00000803(2051)| magic number|\n",
    "|0004   |  32 bit integer | 10000    |        number of images|\n",
    "|0008   |  32 bit integer|  28      |         number of rows|\n",
    "|0012   |  32 bit integer|  28      |         number of columns|\n",
    "|0016   |  unsigned byte|  ??      |         pixel|\n",
    "|0017    | unsigned byte |  ??      |         pixel|\n",
    "||........||\n",
    "|xxxx   |  unsigned byte |  ??      |         pixel|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(dataset=\"training\", digits=np.arange(10), path=\".\"):\n",
    "    \"\"\"\n",
    "    Loads MNIST files into 3D numpy arrays \n",
    "    Adapted from: http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "    \"\"\"\n",
    "    \n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    \n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = np.zeros((N, rows, cols) )\n",
    "    labels = np.zeros((N ) )\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = np.array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the MNIST data set and use load_mnist function to load the raw data and also process it into manageable chunks.<br>\n",
    "Our path is: data/MNIST/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the path for training data starting from the executed ipynb file:data/MNIST/raw/\n",
      "Please enter the path for test data starting from the executed ipynb file:data/MNIST/raw/\n"
     ]
    }
   ],
   "source": [
    "path = input(\"Please enter the path for training data starting from the executed ipynb file:\")\n",
    "train_data, train_label = load_mnist(\"training\",path=path)\n",
    "path = input(\"Please enter the path for test data starting from the executed ipynb file:\")\n",
    "test_data, test_label = load_mnist(\"testing\",path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image data into rows\n",
    "image_vector_size = 28*28\n",
    "train_data = train_data.reshape(train_data.shape[0], image_vector_size)\n",
    "test_data = test_data.reshape(test_data.shape[0], image_vector_size)\n",
    "# Change to float datatype\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    " \n",
    "# Scale the data to lie between 0 to 1\n",
    "train_data /= 255\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_classification_converter(data,classes):\n",
    "    num_classes = len(classes)\n",
    "    representation = np.zeros((len(data),num_classes))\n",
    "    for ele,ind in zip(data,range(len(data))):\n",
    "        representation[ind][int(ele)] = 1\n",
    "    return representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 0. 4. 1. 9. 2. 1. 3. 1. 4.]\n",
      "[[0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "image_size = 784 #28x28\n",
    "batch_size = 20\n",
    "# Change the labels from integer to categorical data\n",
    "lr = np.arange(num_classes)\n",
    "# transform labels into one hot representation\n",
    "y_train_one_hot = one_hot_classification_converter(train_label,lr).astype(int)\n",
    "y_test_one_hot =  one_hot_classification_converter(test_label,lr).astype(int)\n",
    "\n",
    "# shows that one-hot-encoding is correctly applied\n",
    "print(train_label[:10])\n",
    "print(y_train_one_hot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.71518937]\n",
      " [0.60276338 0.54488318]\n",
      " [0.4236548  0.64589411]\n",
      " [0.43758721 0.891773  ]\n",
      " [0.96366276 0.38344152]\n",
      " [0.79172504 0.52889492]\n",
      " [0.56804456 0.92559664]\n",
      " [0.07103606 0.0871293 ]\n",
      " [0.0202184  0.83261985]\n",
      " [0.77815675 0.87001215]]\n",
      "[2 3 8 1 3 3 3 7 0 1]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[8 1 5 6 3 4 2 7 0 9]\n",
      "[[0.0202184  0.83261985]\n",
      " [0.60276338 0.54488318]\n",
      " [0.79172504 0.52889492]\n",
      " [0.56804456 0.92559664]\n",
      " [0.43758721 0.891773  ]\n",
      " [0.96366276 0.38344152]\n",
      " [0.4236548  0.64589411]\n",
      " [0.07103606 0.0871293 ]\n",
      " [0.5488135  0.71518937]\n",
      " [0.77815675 0.87001215]]\n"
     ]
    }
   ],
   "source": [
    "# test code for shuffling data\n",
    "A = np.random.random((10,2))\n",
    "B = np.random.randint(10,size=(10))\n",
    "print(A)\n",
    "print(B)\n",
    "C = np.arange(len(B))\n",
    "print(C)\n",
    "np.random.shuffle(C)\n",
    "print(C)\n",
    "A = A[C]\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21655035 0.13521817 0.32414101 0.14967487 0.22232139]\n",
      " [0.38648898 0.90259848 0.44994999 0.61306346 0.90234858]\n",
      " [0.09928035 0.96980907 0.65314004 0.17090959 0.35815217]\n",
      " [0.75068614 0.60783067 0.32504723 0.03842543 0.63427406]]\n",
      "8.909910008064497\n",
      "8.909910008064495\n",
      "0.4454955004032247\n",
      "0.44549550040322483\n"
     ]
    }
   ],
   "source": [
    "# checking what ndarray.mean() is actually calculating\n",
    "A = np.random.random((4,5))\n",
    "print(A)\n",
    "print(A.sum())\n",
    "sum = 0\n",
    "for row in A:\n",
    "    for ele in row:\n",
    "        sum +=ele\n",
    "print(sum)\n",
    "print(sum/20)\n",
    "print(A.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95894927 0.65279032 0.63505887 0.99529957]\n",
      " [0.58185033 0.41436859 0.4746975  0.6235101 ]\n",
      " [0.33800761 0.67475232 0.31720174 0.77834548]\n",
      " [0.94957105 0.66252687 0.01357164 0.6228461 ]\n",
      " [0.67365963 0.971945   0.87819347 0.50962438]]\n",
      "\n",
      "\n",
      "[[2.60895372 1.92089326 1.88713324 2.70553471]\n",
      " [1.78934625 1.51341485 1.60752785 1.86546453]\n",
      " [1.40215118 1.96354659 1.37327959 2.17786596]\n",
      " [2.58460077 1.93968748 1.01366415 1.86422626]\n",
      " [1.96140221 2.64308026 2.40654828 1.66466579]]\n",
      "\n",
      "[9.12251493 6.77575348 6.91684333 7.40217866 8.67569654]\n",
      "\n",
      "[[0.28599062 0.2105662  0.20686546 0.29657772]\n",
      " [0.26408078 0.22335743 0.2372471  0.2753147 ]\n",
      " [0.20271548 0.283879   0.19854138 0.31486415]\n",
      " [0.34916757 0.26204278 0.13694132 0.25184832]\n",
      " [0.22608008 0.30465338 0.27738963 0.1918769 ]]\n",
      "4.999999999999999\n",
      "[[0.28599062 0.2105662  0.20686546 0.29657772]\n",
      " [0.26408078 0.22335743 0.2372471  0.2753147 ]\n",
      " [0.20271548 0.283879   0.19854138 0.31486415]\n",
      " [0.34916757 0.26204278 0.13694132 0.25184832]\n",
      " [0.22608008 0.30465338 0.27738963 0.1918769 ]]\n",
      "\n",
      "[[0.25215921 0.19246227 0.22769044 0.26324174]\n",
      " [0.17294295 0.15163532 0.19395489 0.18150502]\n",
      " [0.13551997 0.19673589 0.16569187 0.2119009 ]\n",
      " [0.24980546 0.19434534 0.12230278 0.18138454]\n",
      " [0.18957241 0.26482118 0.29036002 0.16196781]]\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# test the softmax function\n",
    "A = np.random.random((5,4))\n",
    "print(A)\n",
    "print()\n",
    "expA = np.exp(A)\n",
    "exp_sumA = np.sum(expA,axis=1)\n",
    "print()\n",
    "print(expA)\n",
    "print()\n",
    "print(exp_sumA)\n",
    "print()\n",
    "cpy_expA = np.copy(expA)\n",
    "for row,ind in zip(expA,range(len(expA))):\n",
    "    expA[ind] = row/exp_sumA[ind]\n",
    "print(expA)\n",
    "print(expA.sum())\n",
    "print(np.transpose(softmax(np.transpose(A))))\n",
    "print()\n",
    "print(softmax(A))\n",
    "print(softmax(A).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.60895372 1.92089326 1.88713324 2.70553471]\n",
      " [1.78934625 1.51341485 1.60752785 1.86546453]\n",
      " [1.40215118 1.96354659 1.37327959 2.17786596]\n",
      " [2.58460077 1.93968748 1.01366415 1.86422626]\n",
      " [1.96140221 2.64308026 2.40654828 1.66466579]]\n",
      "\n",
      "[[2.60895372 1.78934625 1.40215118 2.58460077 1.96140221]\n",
      " [1.92089326 1.51341485 1.96354659 1.93968748 2.64308026]\n",
      " [1.88713324 1.60752785 1.37327959 1.01366415 2.40654828]\n",
      " [2.70553471 1.86546453 2.17786596 1.86422626 1.66466579]]\n",
      "\n",
      "[[0.25215921 0.19246227 0.22769044 0.26324174]\n",
      " [0.17294295 0.15163532 0.19395489 0.18150502]\n",
      " [0.13551997 0.19673589 0.16569187 0.2119009 ]\n",
      " [0.24980546 0.19434534 0.12230278 0.18138454]\n",
      " [0.18957241 0.26482118 0.29036002 0.16196781]]\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# This leads to investigate further; it seems that softmax is columnwise and not rowwise, but our data is rowwise\n",
    "expA = cpy_expA\n",
    "print(expA)\n",
    "print()\n",
    "expA = np.transpose(expA)\n",
    "exp_sumA = np.sum(expA,axis=1)\n",
    "print(expA)\n",
    "print()\n",
    "for row,ind in zip(expA,range(len(expA))):\n",
    "    expA[ind] = row/exp_sumA[ind]\n",
    "expA = np.transpose(expA)\n",
    "print(expA)\n",
    "print(expA.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x226df76e3c8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2 layer Neural network code \n",
    "#initialize random seed\n",
    "\n",
    "\n",
    "#Weight matrix of size 784x10\n",
    "W = np.random.normal(size=(image_size,num_classes))\n",
    "bias = np.zeros(num_classes)\n",
    "learnrate = 0.01\n",
    "error = []\n",
    "final_error = []\n",
    "epoches = 10\n",
    "for e in range(epoches):\n",
    "    # each epoche randomly shuffle the data \n",
    "    tmp_shuffler = np.arange(len(train_label))\n",
    "    train_data = train_data[tmp_shuffler]\n",
    "    train_label = train_label[tmp_shuffler]\n",
    "    y_train_one_hot = y_train_one_hot[tmp_shuffler]\n",
    "    \n",
    "    #defining a for loop from 1 to 60000 where the batch size is 20\n",
    "    for i in range(1,60000,batch_size):\n",
    "        layer_0 = train_data[i:i+batch_size,:]\n",
    "        # check above 2 cells why we need a double transpose here\n",
    "        layer_1 = np.transpose(softmax(np.transpose(np.dot(layer_0,W)+bias)))  \n",
    "        # calculate (teacher-output) for whole batch\n",
    "        absolute_error = np.subtract(y_train_one_hot[i:i+batch_size,:], layer_1)\n",
    "        # calculate MSE\n",
    "        batch_error = (0.5*np.square(absolute_error).sum())/batch_size\n",
    "        #print(\"epoch:\",e,\";batch:\",i,\" error:\",batch_error)\n",
    "        \n",
    "        # calculate general delta rule\n",
    "        delta = layer_1*(1-layer_1)*absolute_error\n",
    "        W_change = learnrate*np.dot(np.transpose(layer_0),delta)\n",
    "        W += W_change\n",
    "        \n",
    "        error.append(batch_error)\n",
    "        \n",
    "    final_error.append(np.mean(error))\n",
    "    error.clear()\n",
    "    \n",
    "plt.plot(final_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
